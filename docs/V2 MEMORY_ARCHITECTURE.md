# Zenna Memory Architecture

> **Last Updated**: February 6, 2026
> **Version**: 1.1

## Core Principle

**Memories are PERMANENT.** Zenna is built for longevity and lifelong AI companionship with never-ending memories. Every fact, preference, relationship, and experience shared with Zenna is treasured and remembered forever.

Memories are ONLY deleted when explicitly requested by the user.

## Architecture Overview

```
┌─────────────────────────────────────────────────────────────────┐
│                      Memory Service                              │
│                 (src/core/services/memory-service.ts)           │
├─────────────────────────────────────────────────────────────────┤
│                                                                  │
│  ┌─────────────────────┐    ┌─────────────────────────────┐    │
│  │   Supabase Store    │    │   Vector Store (RAG)        │    │
│  │  (Structured Data)  │    │   Qdrant OR Pinecone        │    │
│  ├─────────────────────┤    ├─────────────────────────────┤    │
│  │ • session_turns     │    │ • Vector embeddings         │    │
│  │ • conversations     │    │ • Semantic similarity       │    │
│  │ • user settings     │    │ • Memory retrieval          │    │
│  │ • Full-text search  │    │ • Facts & preferences       │    │
│  └─────────────────────┘    └─────────────────────────────┘    │
│                                                                  │
└─────────────────────────────────────────────────────────────────┘
```

## Memory Types

### 1. Conversation Turns
- Every user and assistant message
- Stored in Supabase `session_turns` table
- Also embedded and stored in Vector DB for semantic search
- **Never deleted** (previously trimmed to 40 turns - now permanent)

### 2. Facts (High Importance)
- Family relationships
- Personal milestones
- Important life events
- Stored with `importance: 0.9`
- Tagged for easy retrieval

### 3. Preferences
- User preferences and settings
- Communication style
- Interests and hobbies
- Stored with `importance: 0.8`

### 4. Context
- Conversation summaries
- Topic associations
- Relationship mappings

## Data Flow

### On User Message:
1. Message received by chat API
2. **Semantic Search**: Query vector store for relevant memories
3. **Build Context**: Inject relevant memories into system prompt
4. **Recent History**: Load last 50 turns from Supabase
5. **Send to LLM**: Complete context with memories + history
6. **Store Permanently**: Save to both Supabase AND vector store

### On Assistant Response:
1. Response generated by LLM
2. **Store Permanently**: Save to both Supabase AND vector store
3. No trimming, no deletion

## Vector Store Options

### Option 1: Qdrant (Recommended for Cost Savings)

**Qdrant** is an open-source, Rust-based vector database that can be self-hosted for significant cost savings at scale.

#### Deployment Options:
1. **Qdrant Cloud** (managed): https://cloud.qdrant.io
   - Free tier: 1GB (sufficient for ~500K memories)
   - Paid: ~$25/month for 4GB
2. **Self-hosted on GCP**:
   - Cloud Run: ~$10-30/month (scales to zero)
   - Compute Engine e2-medium: ~$27/month
3. **Self-hosted on AWS**:
   - EC2 t3.medium: ~$30/month
   - ECS Fargate: ~$40/month (managed containers)
4. **Docker (local/development)**:
   ```bash
   docker run -p 6333:6333 -v $(pwd)/qdrant_storage:/qdrant/storage qdrant/qdrant
   ```

#### Environment Variables:
```env
VECTOR_PROVIDER=qdrant
QDRANT_URL=http://localhost:6333  # or your cloud/self-hosted URL
QDRANT_API_KEY=your_api_key       # Required for Qdrant Cloud
QDRANT_COLLECTION=zenna-memories
```

### Option 2: Pinecone (Managed Service)

**Pinecone** is a fully managed vector database - easier to set up but more expensive at scale.

#### Pricing:
- Free tier: 1 index, 100K vectors
- Starter: $70/month, 1M vectors
- Standard: Pay-per-use

#### Environment Variables:
```env
VECTOR_PROVIDER=pinecone
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=zenna-memories
```

#### Pinecone Index Setup:
Create a Pinecone index with:
- **Dimensions**: 768 (for Gemini text-embedding-004) or 1536 (for OpenAI text-embedding-3-small)
- **Metric**: cosine
- **Pod Type**: s1 (starter) or p1 (production)

## Cost Comparison

| Provider | Monthly Cost | Vectors | Best For |
|----------|-------------|---------|----------|
| Qdrant Cloud Free | $0 | ~500K | Development/small scale |
| Qdrant Self-hosted | $27-50 | Unlimited* | Production at scale |
| Pinecone Free | $0 | 100K | Development |
| Pinecone Starter | $70 | 1M | Production (managed) |

*Limited by instance storage

### Cost at Scale Analysis:
- **< 1M vectors**: Pinecone free/starter tier is simpler
- **1-10M vectors**: Qdrant self-hosted saves ~$50-100/month
- **10M+ vectors**: Qdrant self-hosted saves $100s-1000s/month

## Configuration

### Required Environment Variables

```env
# Supabase (required for structured data)
NEXT_PUBLIC_SUPABASE_URL=your_supabase_url
SUPABASE_SERVICE_ROLE_KEY=your_service_role_key

# Vector Provider Selection (default: qdrant)
VECTOR_PROVIDER=qdrant

# Qdrant (recommended)
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=              # Optional for self-hosted
QDRANT_COLLECTION=zenna-memories

# OR Pinecone
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=zenna-memories

# Embedding Provider (required for vector storage)
GOOGLE_AI_API_KEY=your_gemini_key  # Recommended (cheaper)
# OR
OPENAI_API_KEY=your_openai_key
```

## Self-Hosting Qdrant on GCP

### Option A: Cloud Run (Recommended for variable usage)

```bash
# Deploy Qdrant to Cloud Run
gcloud run deploy qdrant \
  --image qdrant/qdrant \
  --port 6333 \
  --memory 2Gi \
  --cpu 1 \
  --min-instances 0 \
  --max-instances 1 \
  --allow-unauthenticated
```

### Option B: Compute Engine (Recommended for consistent usage)

```bash
# Create VM with Qdrant
gcloud compute instances create-with-container qdrant-vm \
  --container-image=qdrant/qdrant \
  --machine-type=e2-medium \
  --boot-disk-size=50GB \
  --tags=qdrant

# Allow traffic on port 6333
gcloud compute firewall-rules create allow-qdrant \
  --allow tcp:6333 \
  --target-tags=qdrant
```

## Migration from Previous Architecture

### What Changed:
1. **Removed `trimSessionHistory`** - No more deletion of old turns
2. **Added Memory Service** - Unified interface for memory management
3. **Added Vector Store Integration** - Semantic search over all memories
4. **Added Qdrant Support** - Cost-effective self-hosted option
5. **Added Memory Context Injection** - Relevant memories injected into prompts

### For Existing Users:
- All existing memories in `session_turns` are preserved
- New memories will also be stored in vector DB (if configured)
- Users may need to re-share important information that was previously deleted

## API Usage

### Memory Service Methods

```typescript
import { createMemoryService } from '@/core/services/memory-service';

const memoryService = createMemoryService();
await memoryService.initialize();

// Check which vector provider is active
console.log('Vector provider:', memoryService.getVectorProvider());
// Output: 'qdrant', 'pinecone', or 'none'

// Store a conversation turn
await memoryService.addConversationTurn(userId, 'user', 'My daughter Sarah just turned 5!');

// Store an important fact
await memoryService.storeImportantFact(userId, 'User has a daughter named Sarah, born 2021', {
  topic: 'family',
  tags: ['family', 'children', 'daughter'],
});

// Search memories
const memories = await memoryService.searchMemories(userId, 'tell me about my family');

// Build context for LLM
const context = await memoryService.buildMemoryContext(userId, userMessage);
```

## Cost Optimization Tips

1. **Use Gemini embeddings** (~$0.00002 per 1K tokens vs OpenAI ~$0.00013)
2. **Self-host Qdrant** for production workloads
3. **Use Cloud Run** if usage is variable (scales to zero)
4. **Set appropriate similarity thresholds** (0.6-0.7) to reduce noise
5. **Limit topK results** (5-10) for performance
6. **Batch embedding operations** where possible

## Future Enhancements

1. **Memory Summarization**: Periodically summarize old conversations
2. **Memory Importance Decay**: Lower importance of old, unreferenced memories
3. **Memory Clustering**: Group related memories together
4. **User Memory Management**: UI for users to view/manage their memories
5. **Memory Export**: Allow users to export their memory graph
6. **Local-First**: SQLite + sqlite-vss for offline/local operation

## Immutable Rules

From the master system prompt:

1. Zenna NEVER forgets
2. All memories are permanent unless explicitly requested for deletion
3. Zenna preserves all personal information, family relationships, preferences, and life events
4. Memories are sacred knowledge to be treasured eternally
